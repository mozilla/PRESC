{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting and Handling Covariates in Data\n",
    "\n",
    "Data taken from: https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data\n",
    "\n",
    "**Reason for not using the already present datasets:**\n",
    "\n",
    "- According to [issue #3](https://github.com/mozilla/PRESC/issues/3) the solutions on `eeg.csv` and `vehicles.csv` do not show a significant change in the evaluation metrics when the ratio chosen to split the data is changed. For example, let us consider `vehicles.csv`, the following are the results explaining the variation in the evaluation metric when train-test splitting ratio is changed:\n",
    "<img src='data/Capture1.PNG'>\n",
    "    \n",
    "    - As we can see that the variation is not very significant\n",
    "    \n",
    "- In the already available datasets the choice of train-test split was not affecting model performance to a great extent.\n",
    "- So we need a dataset which is more complicated. This data set based on predicting the probability that an auto insurance policy holder files a claim by Porto Seguro has data which has covariate shift. So the model's performance will highly degrade on choosing just any random train-test split ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the [previous algorithm](https://github.com/mozilla/PRESC/blob/0785213e5c65e6f799c3df829602f3c624a53c4b/dev/Sidrah-Madiha/Traversal_of_the_space_of_train_test_splits/vehicles_dataset_classifer_for_testing_issue%233.ipynb) as used to predict on `vehicles.csv` the following result is obtained:\n",
    "<img src='data/Capture2.PNG'>\n",
    "<img src='data/Capture3.PNG'>\n",
    "\n",
    "\n",
    "**The approach used does the following:**\n",
    "1. Fetch data\n",
    "2. Add a column to describe if the data point belongs to train data or not\n",
    "3. Combine train and test data\n",
    "4. Building RandomForestClassifier\n",
    "5. Using StratifiedKFold to perform train-test split\n",
    "6. Predicting the probability of a data point from the entire data set belonging to train (calculating covariance)\n",
    "7. Improving performance by assigning importance weight using Density Ratio Estimation\n",
    "8. Using the above weights, running RandomForestClassifier again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Fetching and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.csv.zip to ../../datasets\\safe-driver\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/30.0M [00:00<?, ?B/s]\n",
      "  3%|3         | 1.00M/30.0M [00:01<00:42, 722kB/s]\n",
      "  7%|6         | 2.00M/30.0M [00:02<00:33, 887kB/s]\n",
      " 10%|#         | 3.00M/30.0M [00:02<00:27, 1.04MB/s]\n",
      " 13%|#3        | 4.00M/30.0M [00:03<00:21, 1.24MB/s]\n",
      " 17%|#6        | 5.00M/30.0M [00:03<00:20, 1.27MB/s]\n",
      " 20%|##        | 6.00M/30.0M [00:04<00:21, 1.17MB/s]\n",
      " 23%|##3       | 7.00M/30.0M [00:05<00:21, 1.11MB/s]\n",
      " 27%|##6       | 8.00M/30.0M [00:06<00:20, 1.13MB/s]\n",
      " 30%|###       | 9.00M/30.0M [00:07<00:17, 1.27MB/s]\n",
      " 33%|###3      | 10.0M/30.0M [00:08<00:15, 1.38MB/s]\n",
      " 37%|###6      | 11.0M/30.0M [00:08<00:14, 1.37MB/s]\n",
      " 40%|####      | 12.0M/30.0M [00:09<00:11, 1.68MB/s]\n",
      " 43%|####3     | 13.0M/30.0M [00:09<00:09, 1.92MB/s]\n",
      " 47%|####6     | 14.0M/30.0M [00:09<00:07, 2.16MB/s]\n",
      " 50%|#####     | 15.0M/30.0M [00:10<00:06, 2.30MB/s]\n",
      " 53%|#####3    | 16.0M/30.0M [00:10<00:05, 2.59MB/s]\n",
      " 57%|#####6    | 17.0M/30.0M [00:10<00:04, 2.86MB/s]\n",
      " 60%|######    | 18.0M/30.0M [00:11<00:04, 2.99MB/s]\n",
      " 63%|######3   | 19.0M/30.0M [00:11<00:03, 3.18MB/s]\n",
      " 67%|######6   | 20.0M/30.0M [00:11<00:03, 3.39MB/s]\n",
      " 70%|#######   | 21.0M/30.0M [00:11<00:02, 3.33MB/s]\n",
      " 73%|#######3  | 22.0M/30.0M [00:12<00:02, 3.23MB/s]\n",
      " 77%|#######6  | 23.0M/30.0M [00:12<00:02, 3.01MB/s]\n",
      " 80%|########  | 24.0M/30.0M [00:13<00:02, 3.03MB/s]\n",
      " 83%|########3 | 25.0M/30.0M [00:13<00:01, 2.98MB/s]\n",
      " 87%|########6 | 26.0M/30.0M [00:13<00:01, 2.99MB/s]\n",
      " 90%|######### | 27.0M/30.0M [00:14<00:01, 2.43MB/s]\n",
      " 93%|#########3| 28.0M/30.0M [00:14<00:00, 2.34MB/s]\n",
      " 97%|#########6| 29.0M/30.0M [00:15<00:00, 2.21MB/s]\n",
      "100%|##########| 30.0M/30.0M [00:15<00:00, 2.09MB/s]\n",
      "100%|##########| 30.0M/30.0M [00:15<00:00, 1.97MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading test.csv.zip to ../../datasets\\safe-driver\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/44.4M [00:00<?, ?B/s]\n",
      "  2%|2         | 1.00M/44.4M [00:00<00:25, 1.76MB/s]\n",
      "  5%|4         | 2.00M/44.4M [00:01<00:23, 1.87MB/s]\n",
      "  7%|6         | 3.00M/44.4M [00:01<00:21, 1.98MB/s]\n",
      "  9%|9         | 4.00M/44.4M [00:01<00:19, 2.16MB/s]\n",
      " 11%|#1        | 5.00M/44.4M [00:02<00:21, 1.96MB/s]\n",
      " 14%|#3        | 6.00M/44.4M [00:02<00:19, 2.11MB/s]\n",
      " 16%|#5        | 7.00M/44.4M [00:03<00:17, 2.28MB/s]\n",
      " 18%|#8        | 8.00M/44.4M [00:03<00:16, 2.34MB/s]\n",
      " 20%|##        | 9.00M/44.4M [00:04<00:15, 2.40MB/s]\n",
      " 23%|##2       | 10.0M/44.4M [00:04<00:14, 2.45MB/s]\n",
      " 25%|##4       | 11.0M/44.4M [00:05<00:15, 2.31MB/s]\n",
      " 27%|##7       | 12.0M/44.4M [00:06<00:20, 1.69MB/s]\n",
      " 29%|##9       | 13.0M/44.4M [00:07<00:25, 1.30MB/s]\n",
      " 32%|###1      | 14.0M/44.4M [00:08<00:25, 1.24MB/s]\n",
      " 34%|###3      | 15.0M/44.4M [00:08<00:22, 1.34MB/s]\n",
      " 36%|###6      | 16.0M/44.4M [00:09<00:22, 1.30MB/s]\n",
      " 38%|###8      | 17.0M/44.4M [00:10<00:21, 1.31MB/s]\n",
      " 41%|####      | 18.0M/44.4M [00:11<00:23, 1.16MB/s]\n",
      " 43%|####2     | 19.0M/44.4M [00:12<00:22, 1.16MB/s]\n",
      " 45%|####5     | 20.0M/44.4M [00:13<00:19, 1.30MB/s]\n",
      " 47%|####7     | 21.0M/44.4M [00:13<00:17, 1.41MB/s]\n",
      " 50%|####9     | 22.0M/44.4M [00:14<00:15, 1.50MB/s]\n",
      " 52%|#####1    | 23.0M/44.4M [00:14<00:13, 1.65MB/s]\n",
      " 54%|#####4    | 24.0M/44.4M [00:15<00:15, 1.37MB/s]\n",
      " 56%|#####6    | 25.0M/44.4M [00:17<00:22, 911kB/s] \n",
      " 59%|#####8    | 26.0M/44.4M [00:19<00:25, 767kB/s]\n",
      " 61%|######    | 27.0M/44.4M [00:21<00:23, 791kB/s]\n",
      " 63%|######3   | 28.0M/44.4M [00:21<00:19, 897kB/s]\n",
      " 65%|######5   | 29.0M/44.4M [00:22<00:16, 978kB/s]\n",
      " 68%|######7   | 30.0M/44.4M [00:23<00:13, 1.12MB/s]\n",
      " 70%|######9   | 31.0M/44.4M [00:23<00:10, 1.35MB/s]\n",
      " 72%|#######2  | 32.0M/44.4M [00:24<00:08, 1.62MB/s]\n",
      " 74%|#######4  | 33.0M/44.4M [00:24<00:06, 1.95MB/s]\n",
      " 77%|#######6  | 34.0M/44.4M [00:24<00:04, 2.19MB/s]\n",
      " 79%|#######8  | 35.0M/44.4M [00:26<00:07, 1.31MB/s]\n",
      " 81%|########1 | 36.0M/44.4M [00:27<00:06, 1.35MB/s]\n",
      " 83%|########3 | 37.0M/44.4M [00:27<00:05, 1.45MB/s]\n",
      " 86%|########5 | 38.0M/44.4M [00:28<00:04, 1.37MB/s]\n",
      " 88%|########7 | 39.0M/44.4M [00:28<00:03, 1.51MB/s]\n",
      " 90%|######### | 40.0M/44.4M [00:29<00:02, 1.56MB/s]\n",
      " 92%|#########2| 41.0M/44.4M [00:30<00:02, 1.53MB/s]\n",
      " 95%|#########4| 42.0M/44.4M [00:31<00:01, 1.53MB/s]\n",
      " 97%|#########6| 43.0M/44.4M [00:31<00:00, 1.67MB/s]\n",
      " 99%|#########9| 44.0M/44.4M [00:32<00:00, 1.68MB/s]\n",
      "100%|##########| 44.4M/44.4M [00:32<00:00, 1.90MB/s]\n",
      "100%|##########| 44.4M/44.4M [00:32<00:00, 1.44MB/s]\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "import os\n",
    "import requests\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# downloading data\n",
    "def extract_data(file_name, file_path):\n",
    "    !kaggle competitions download porto-seguro-safe-driver-prediction -f $file_name -p $file_path --force\n",
    "\n",
    "train = 'train.csv'\n",
    "test = 'test.csv'\n",
    "\n",
    "raw_data_path = os.path.join('../../datasets', 'safe-driver', 'raw')\n",
    "extract_data(train, raw_data_path)\n",
    "extract_data(test, raw_data_path)\n",
    "\n",
    "# extracting train data\n",
    "from zipfile import ZipFile\n",
    "zf = ZipFile('../../datasets/safe-driver/raw/train.csv.zip', 'r')\n",
    "zf.extractall('../../datasets/safe-driver')\n",
    "zf.close()\n",
    "\n",
    "# extracting test data\n",
    "zf = ZipFile('../../datasets/safe-driver/raw/test.csv.zip', 'r')\n",
    "zf.extractall('../../datasets/safe-driver')\n",
    "zf.close()\n",
    "\n",
    "# loading data\n",
    "train = pd.read_csv('../../datasets/safe-driver/train.csv', index_col='id')\n",
    "test = pd.read_csv('../../datasets/safe-driver/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "id                                                                              \n",
       "7        0          2              2          5              1              0   \n",
       "9        0          1              1          7              0              0   \n",
       "13       0          5              4          9              1              0   \n",
       "16       0          0              1          2              0              0   \n",
       "17       0          0              2          0              1              0   \n",
       "\n",
       "    ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ...  \\\n",
       "id                                                              ...   \n",
       "7               0              1              0              0  ...   \n",
       "9               0              0              1              0  ...   \n",
       "13              0              0              1              0  ...   \n",
       "16              1              0              0              0  ...   \n",
       "17              1              0              0              0  ...   \n",
       "\n",
       "    ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "id                                                                   \n",
       "7            9           1           5           8               0   \n",
       "9            3           1           1           9               0   \n",
       "13           4           2           7           7               0   \n",
       "16           2           2           4           9               0   \n",
       "17           3           1           1           3               0   \n",
       "\n",
       "    ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "id                                                                   \n",
       "7                1               1               0               0   \n",
       "9                1               1               0               1   \n",
       "13               1               1               0               1   \n",
       "16               0               0               0               0   \n",
       "17               0               0               1               1   \n",
       "\n",
       "    ps_calc_20_bin  \n",
       "id                  \n",
       "7                1  \n",
       "9                0  \n",
       "13               0  \n",
       "16               0  \n",
       "17               0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "id                                                                      \n",
       "0           0              1          8              1              0   \n",
       "1           4              2          5              1              0   \n",
       "2           5              1          3              0              0   \n",
       "3           0              1          6              0              0   \n",
       "4           5              1          7              0              0   \n",
       "\n",
       "    ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ps_ind_10_bin  \\\n",
       "id                                                                              \n",
       "0               0              1              0              0              0   \n",
       "1               0              0              0              1              0   \n",
       "2               0              0              0              1              0   \n",
       "3               1              0              0              0              0   \n",
       "4               0              0              0              1              0   \n",
       "\n",
       "    ...  ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "id  ...                                                                   \n",
       "0   ...           1           1           1          12               0   \n",
       "1   ...           2           0           3          10               0   \n",
       "2   ...           4           0           2           4               0   \n",
       "3   ...           5           1           0           5               1   \n",
       "4   ...           4           0           0           4               0   \n",
       "\n",
       "    ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "id                                                                   \n",
       "0                1               1               0               0   \n",
       "1                0               1               1               0   \n",
       "2                0               0               0               0   \n",
       "3                0               1               0               0   \n",
       "4                1               1               0               0   \n",
       "\n",
       "    ps_calc_20_bin  \n",
       "id                  \n",
       "0                1  \n",
       "1                1  \n",
       "2                0  \n",
       "3                0  \n",
       "4                1  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Indicator for Source of Origin\n",
    "Adding a feature ‘is_train’ in both train and test data. Value for this feature will be 0 for test and 1 for train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a coulmn to test and train set that tells if the data point belongs to either\n",
    "\n",
    "# data point does not belong to train\n",
    "test['is_train'] = 0\n",
    "# data point belongs to train\n",
    "train['is_train'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Combining train and test\n",
    "Combining both the datasets. Also since train data has the original ‘target’ variable which is not present in test, we have to drop that variable too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# combining train, test\n",
    "df_combine = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "# dropping ‘target’ column as it is not present in the test\n",
    "df_combine = df_combine.drop('target', axis =1)\n",
    "\n",
    "y = df_combine['is_train'].values #labels\n",
    "x = df_combine.drop('is_train', axis=1).values #covariates or our independent variables\n",
    "tst, trn = test.values, train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Building and Testing a Classifier\n",
    "Random Forest Classifier is used to predict the labels for each row in the combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and testing a classifier\n",
    "rfc = RandomForestClassifier(n_jobs=3, max_depth=5, min_samples_leaf = 5)\n",
    "\n",
    "#creating an empty prediction array\n",
    "predictions = np.zeros(y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Performing Train-Test Split\n",
    "We are using stratified 4 fold to ensure that percentage for each class is preserved and we cover the whole data once. For each row the classifier will calculate the probability of it belonging to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# initializing model\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=100)\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(x, y)):\n",
    "    X_train, X_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    " \n",
    "    rfc.fit(X_train, y_train)\n",
    "    probs = rfc.predict_proba(X_test)[:, 1] #calculating the probability\n",
    "    predictions[test_idx] = probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Interpreting the Results\n",
    "If the classifier is able to classify the rows into train and test with good accuracy, our AUC score should be on the higher side (greater than 0.8). This implies strong covariate shift between train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5007147418638885\n"
     ]
    }
   ],
   "source": [
    "print('ROC-AUC:', roc_auc_score(y_true=y, y_score=predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference: AUC value of 0.49 implies that there is no evidence of strong covariate shift. This means that majority of the observations comes from a feature space which is not specific to test or train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Improving Performance\n",
    "1. Dropping of drifting features\n",
    "    - Note: This method is applicable to the situation where you witness covariate shift.\n",
    "    - Extract feature importance from the random forest classifier object that we have built in the previous section\n",
    "    - The top features are the ones which are drifting and causing the shift.\n",
    "    - Drop those features one by one and compute the model performance\n",
    "2. Importance weight using Density Ratio Estimation\n",
    "    - Note: This method is applicable irrespective of whether there exist a covariate shift or not.\n",
    "\n",
    "#### Let’s look at the predictions that we have calculated in the previous section. For each observation, this prediction tells us the probability that it belongs to the training data according to our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39914871, 0.40063592, 0.40234769, 0.40055795, 0.39907569,\n",
       "       0.40114795, 0.39854171, 0.40007704, 0.39976834, 0.39438289])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row of training data we calculate a coefficient `w = P(test)/P(train)`.\n",
    "This `w` tells us how close is the observation from the training data to our test data.\n",
    "#### We can use this w as sample weights in any of our classifier to increase the weight of these observation which seems similar to our test data. Intuitively this makes sense as our model will focus more on capturing patterns from the observations which seems similar to our test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488028,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7effb5c262e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "predictions_train = predictions[:len(tst)]  # filtering the actual training rows\n",
    "weights = (1./predictions_train) - 1. \n",
    "weights /= np.mean(weights) # Normalizing the weights\n",
    "\n",
    "plt.xlabel('Computed sample weight')\n",
    "plt.ylabel('# Samples')\n",
    "sns.distplot(weights, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference:\n",
    "- Higher the weight for the observation, more is it similar to the test data\n",
    "- Almost 70% of training samples have sample weight of close to 1 and hence comes from a feature space which is not very specific to train or test high density region. This is in line with the AUC value that we have calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Passing the Weights Calculated in the Model Fit Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    143380\n",
      "           1       0.38      0.00      0.00      5423\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    148803\n",
      "   macro avg       0.67      0.50      0.49    148803\n",
      "weighted avg       0.94      0.96      0.95    148803\n",
      "\n",
      "[[143375      5]\n",
      " [  5420      3]]\n"
     ]
    }
   ],
   "source": [
    "# instantiating model\n",
    "m = RandomForestClassifier(n_jobs=3, \n",
    "                           min_samples_split= 13, \n",
    "                            n_estimators = 300,\n",
    "                            max_depth= 10,\n",
    "                            max_features= 13\n",
    "                          )\n",
    "\n",
    "# splitting train and test data\n",
    "train_x = train.drop('target', axis=1)\n",
    "train_y = train.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, random_state = 42, stratify=train_y)\n",
    "\n",
    "# fitting on train data\n",
    "m.fit(X_train, y_train, sample_weight=weights[:len(X_train)])\n",
    "\n",
    "# predicting on test data\n",
    "y_pred = m.predict(X_test)\n",
    "\n",
    "# calculating classification report\n",
    "eval_report = classification_report(y_test, y_pred)\n",
    "print(eval_report)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the very significant improvement in f1-score which now is 0.96 and was 0.52 using the regular methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

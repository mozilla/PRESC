{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log loss: Handling the trade-off between accuracy and confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the study where a number of estimators were compared based on their prediction probabilities, it was realised that a model can be seen to have a high accuracy and very poor prediction quality at the same time. Accuracy is simply a measure of how many row labels(target variables) were gotten right. However, in the case of an imbalanced data set, the accuracy is largely dependent on the majority class and it is a poor indicator of the performance of the model."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAA6CAIAAADk0xMXAAAVBUlEQVR4Ae1dLbSjsBJ+51TW1VYiKyuRSCQSiURWYnFIJBKJxSGRSCQyEhvNeefdb9+3s4H2Utp7270bRE8akslkknyZmfzwn8k+7ySBqqqiKEqSBExprcuyDMMwTVP98bwTs5YXK4E3lcB/3pSvf5ity+VyOBz6vp+mSWs9TdPlcmH4HxaMrbqVwFoJWFxbK6nvSae1zvM8DMM4jgFqSqmyLL+ndFuKlcDPkIDFtfdqx6Zpuq7r+/5wOCilpmmq6xq623sxarmxEnhjCVhce6/GyfMcfjTf99M0naYpyzIobu/FqOXGSuCNJWBx7b0aJ8syMNQ0zfF41Foz5r0YtdxYCbyxBCyuPadxnrJYCecalwjO53OWZUVRPIdFS8VK4J+RgMW1R5saiFaW5YPQprVuPx5anWVZcmH0US5tfiuBf0kCFtceau2mafI8D4Jgv9+P4/gIra7rgiAoigK4BpQ8n88PwuUjLNm8VgJ/qQQsrm1vOK11//HUdf0UXDP0tWmasCS6nUWb00rgn5SAxbVHm11r/RRcIx9U0Ki48ZUNWAlYCayRgMW1NVL6JM1zce2TwuxrKwErgc8kYHHtMwmteG9xbYWQbBIrge+TgMW1J8ja4toThGhJWAk8TwIW154gyw24xs0c3K3GgHx1jTnrersmGRtvJTBNk8W1J3SDu3Ct7/ujeA6Hw/F4lL/4K2MQZrLj8eg4zjAMT2DdkrAS+IkSsLj2hFa9C9e01r7v7z6eOI7HccQC6OLv+PH0fV/XNe75OB6PyMs72p5QAUvCSuBnScDi2hPa815cG4YB8LTf7+u6XmN4kkulVFEUjuMcj8cHdwKTpg1YCfwwCVhce0KD3oVrKK+qKqhdjuOs3HzLfW3Yr+t5nr2X7QmNZ0n8RAks4Npd6sM1mTyFyDXi7xOvlOq6LkmS3W5XVVXf9yt1KK11FEWAtjAMN4hrHMcoiq6JAqdNq6q6luDT+A0sfUqz6zoeFPs0MRJorYdhwPVNK7NsSzaOY5qmK5tvWxHbclVV1TTNp83xaYL1pc9F8UTi69mYp1zsCVrrecP9xjWlVBRFuENiTvGumKqqgiA4n88//kJEnA/NxdP3/cpOMI7j+XwGtOV5zvXQlaLWWjdNc20cDsMQRdFKTuYlaq2TJHFddxvmzglO0zQMA/yJi29vR5Zl+aX3mmit4ziWd69DdOM4rm/Q21XY/FZrfblcuq5bpFCWpe/75/N5pda/SERGXivuHUQxTVNRFDBTZN/uug535bMiv3FNaz2O4+FweNC6gblUliWuD2NJNiAlgFZp23a/3+92u8PhcK3jylxGWDat8SoMwwcXTMdxjOPY8zyD8ra/AA7U8Qbbi8TRo4g7i2kejCzLUk4tUBLrug6CIAzDB4k/kh2yUkotTjCQTF3XvF35kbIwsxqimKYJy1a+78M+uLf5HmTJyA5Dx+jbuKZQWie/cQ0V2O12TwH+y+USBIHBk/07l0CaplDZXNd9Vo+p6zqO43lZ98ZkWfYsXGvb9kGAaJpmvQaqtZa9/HbFx3F0XVdqvjDE6rr2ff9NunGSJNc01r7v9/v9U4btOI6e50lSSqksy+q69jzvwRa83Qrr3y52b1g/GEFa6z9wDQtt6wtYTAnST7FnF+n/sEitted5gLbL5cKG2VxNrXUQBNs0I6PQNE2fhWtRFNV1bdC/66/W2nVdpdQa9IcQVtKvqopfyWEWlPJyfY389H2PtphXX34Ng+m3BaqqMgw6rla9jyi01ufzWc5D0DTjOGYf+wPXwjC85oqeS5OCM15prZVSh8OhbVumYYBiYgwDt18x2c8LyG0fTdM8WMFxHB3HMRrlXucdeFjENfgr5vRRBOOx8w50MJdKLQDxTHyj6SkNWLKwFhl5LbAe17TWYRheU+583/86JYXVv1YLGY/BvOiwXsS1G80kO8M4jrJdgiB4uSjWiCWKorn2ii/tonZ/4NrxeMS9r+yjWuuiKNI0LYpCOjhQNtx1RVHked58PGgJGPxIQy6HYUjTFB52+S0S+DJQBJyCEom7rsOrLMuujXkWIfuBEV6TxsjyPX/BWFmWcLSt3/ZxjT1YT3wLyMC2XmnH9X1vzMzMwoDENYwTtGBZlmmayp13uME8y7I8z5MkyfO8LEvP81C7rutwQSYps19lWYYdeUVRXC6Xa+oY6GA9ikRuBNbj2jRNx+MRY3veSb5OSanruiiKKIrQ2zEK5mqjrGMYhou+b2mHogoYs/CUZVnGAYVV8svlAmnneV4URRiGUEHGcTydTobrigx8kSjQc9BnlFJg6XK5YL86SzcCEJ0ROQyD4ziI/I1rwzAYzjW46PClcXjfqP5hMY52AWYMfmHkcrn4vs9Scf+i67o0ji6XCz62hFFHJzf2LgzDgOZRSgVBwPA112nTNADE8vqDlpt3XDL58gC3fTzo0MmyzACsvu/LskSvpRwkZl2ru/SvASm4FAU1B3MmQMr3fYg3SRK0GlcSMXhkKcMwlGUJRTVJEgy8OecyyzRNbdsa+Ggk4N/1uKaUurHA9UWDue977Hc5n8+crbMsc12XVZgHko9nHm/oa3mecwJD0xAu+77nCby2bU+nk1JqGAbIfxiG0+m0OEYgz69QXbEogZ5AqEnT1OjDRq2bplmUFa93/Y1rZVkS7aCvQdCsp9b6eDzCgoWxQ5WVhicSu65L2JqmCWYI9Ub4dCnBrusYxl4TTi9FUWCEAEavVbVpGgAa0G3+W5blhtVGQ5Rf/VcpdTqd5LaPbSXGcQzhIzvmQ0wth8OBs7HneUayeXES+8qyPJ1OMk3TNNQu0eKYpdq2lQVN05SmqbGOUZalUgopaQfVdS0taHY8Ftr3/el0Yvdg/DywHtcwvOcUEPNFuIbteNCz0CI4XScdrPPqZ1lmIAvSSFwDQEhzFUMV6Jll2fl8xuhGPO2zaZrkSJwL5CtEAdgdx7FpmsPhwJatqur2BIZD1nMmj8cj6v4b16KPh0kBVUQuwNN+v8eMnWUZZzkot4fDAVLGZhHqBfgCJhODfp7nSA/1+3A4YGBwhgcp7OP3fT/Pc/Z+cviUQNu2cRxHURRff2AcARpup5zTWOkPQleT2z421zcMQ1ko3J3TNCVJQscz2gh9HX1r8bSpxLUgCKQOjv1oPAfmeR4pGH0URfMtWg21oz6I5s6yzHEc6g40Y9nQSikmYCQCeZ5fxBPHseM4IuJ/QTqVZV7M/GBAxiP86WCGf2be7oiJoihJkjlxGFlU0GDjO45DDsuynM/imObRVSSrEtfwrR8CBJK5rot5BbgGfgzVhOqwpCzDEMW8LkzzqSigjhkU0BOSJJG9K01TznBYMJnnOhwOLJqB0+mEPcy/ce10OlGlwv43uXgM8Nrtdm3bYm6huYT9vlw4k841tAG2d7I9YN5y3sAnzT3POxwOHCdIDF3Ddd39fk8kZh1kwKi2fHU7PI5j13Vt23azh5EkjsSzhLci5Mx5mxO8xbYP2nRrshhpoiiiQwCvoEbJ9oWixN4vffySmsQ113XZ4kgzDMN+v0efKcuSWyWAJigUKZMkmY9S9CKJd2EYcrML4VjyAwcK2TZeoRn6vkeDep6HMH67rlucKmDbSlIy/Cmu4cAJu8q8K1zrAFjeZUt1XSf3oC22CHFNcggHEYcqFA6KCF2XbQcBwnYBoCMlkj2iuqK95tWXg4tai+QfRXueR1FM0xQEAfHkWk8wVCXQdBwHtfuFa0qp3W4HxxaqmiSJtDsAXgBRrfXpdKKliQ5K25jQSzXHcRzJNCYKZB/HkXr4OI5BEHDvn1KKQh+G4Xw+SzWEogFjwf8fbDiCcoE4xNATxIxvFQAKoC7wemxmb9ELo5Ta7/d0XKZpCvcEOg3lbBQqcS0MQ9nVOJygYuDcRZqm+OApZwIQTNN0vs4+juPxeKTOiL/oJ+DKIIIS6bIwWDX+rrdDu66jamAQwQAzTL95mm0xaBEOdWkhqo9nTjbLsrkYIRZiIvQ1ehsgw/P5DBcbNqPBSY8VG1kKvG9zsSMNRpNM/6wwLTwUjZ4AU52gZnAFk3nOAB0gv3ANxwOmaYKDGbYJJ08YoY7j0Cx1XZfK3TAMh8OBHRSOG6ha1NfkOg48NZg8MVrINFbTmEtO8jc2QGFyg25/7RdFsKC5RN4hpq5rqKWP8Am3sVEdKGhUmWk2woHt+z6awyhX4lpVVbABKUkZk2UZ5ydZNBIvrmMaGkpVVfCdjeOI1TrZZ0CzbdtFb7EsEeH1uIZRZFScBD/V15jy3gCcayzX930413AEMggCTkKsEVfbjLK4HgoUcBwHthiIY2EEw7NtWw5bvCUDuEzhxpz6RVteYAjS3w9LEeuTOEUgd6Wx4k3TcJZl5DRN+/0eNfqFa1VVwZ1BXzLc2JjJsUzJVygbFjtOeEifH+6ZGIahqiqUgUVZhLuuc10XyjlOotETN44jF0aN0xJ933NFXFbjJ4W7ruOyzCP1wqYKgwI6N1oTjgLoWUVRYFXHGEVAwCRJ+AFTY3FcKeX7PpdH0X/iOIYRWhQFVQZ44uZ6VpZl3OQ4DIPneegJTdNw/5CsBWZKY/1BJpDh9bg2TdP5fF5cVsKW6cXxI8vaFgaeYjqBRxJKg2wRSRlW0fwAPHGBBi9OjFIHT5KE66Gwe+D7S5IkyzJUHGMTpvENUcA9gsSStwfDaZryHOEwDNw4Udc1jjmzm7GgNE2lBwPxsuf/wjVuepT1bNsWpzeSJKE6BhJaa+yOwVYmOYs2TXO5XOQFDND+so8nTVO5Rwk7VnCqmXM+ucQ2KGx5W3SOsJ7fH8AiTtu2RlfTWsOngI+BrmEM0+zpdJLW+pqMi2ngJWC3ZpqyLNma3LE1jiP2uxmdFefew48njmMIH5oUtrAlScIJCfNcGIbwo+FUqeM4SEDtmwMPLAVBgI1URVEkSdJ1HUcXoZbMIxCGIT3rxivj7124BjakBDDjxnEchmEQBMBrmcAo7t6/cDtgcz/2mtFBNo5j27bzNRPIBM0qiyvLEnxKg6auaxib2PtJzruuC8MQc08cx0EQOI4j9RWMXEl/HMckSaIogh0ax/HiSojMcm8Y1kPx8SRJwn6C5RRo8awCiAdBAERiWZj2AHbmOSr6ekmFMcwvA3jr+76BncxFOsi1GI9IvprTN4jIBC8MK6Ww9RQ3FJETIP75fPZ9nzo/3y4GcCiPk+pimvWRGJM04iBY+HEQTpKEPiPutmdnMgoyhG80Ft7Wdc0NU8iOTibXGYCGJM7FuHm7YxtQGIZ0sCKXUsrzvNvbNUkf9eLf24Gu68DqvLIyo/FWvtoQhoKM6mdZJhnAZnqjRSDkxYLmjCFGgiDmTs/zDHcBHFVM2batbDUUN6e/yMa2SGNp3igLOx/ZE/BWKSVdZCzX9336K3/pa4sVMMpgflgKmIdh4HBmZpp54Bq1ecq/JQZKDSCMrisEoJauqQg0ZYzYNenXpOn7nvuZsS+JFp9SCmYXmgNaAHb8326ga2/hBIEnFGnw27atXLmH3Uoi0rnGSAaiKMKGRCrpVPnXVB9pmHdNliAIDBxZk2tzGuzMgMaBFuEIki0C+hBLGIbSllosmgI03iK+73t6FUiZxTHLDVFco8+8GwLG0jwZQyCKoqqqYJtziMGAM5jh5IRkf+DaGrYw0+IgFLbRSj12DYUfk2YYhqIosizb7/ccFRA3V4dvVBYp8zyHs9ZopxsZ8QqK4bXRm2UZ/DWwi+GTRntx8Qd0oEkZ0/inpcsEwCy4U1ELTPvSUgAwYReoUipJEsdxqEVKatj3k2UZhzpc2l/qYO37Hp67e1vB4HzlXxQHHSqOY8N/hONoskWapjFMopUFyWRQ5HkFI6y8JEmM8Qvn5lyPlqSeFUZPwEWNi5KvqipNU/YE8My9+mQDyoF06d6NazATcIwLne97RMA6vElAa13Xdd/3WA6mYY9BuHJbCRZAP52HF6uMQ2Z4Ne8TaGmgHpoMx3gX1weQfU5ksVwjEq0/jmNVVXmeY0zijNQ8JfxoVVVlWYZNIbSAjIqALBlDRoPgE/9ikqDx/kTK10hBXHmec0ZESlaZw0opBR/FtgYyyLZtK25BzQkZkk8oyzLmi8KArcWeYLDNvzilboiiKAquUiLl3bj2RTX8G8ny9D78r5R1XdeLi0qyjji9cDweDe1JprkR7vtebrVZTImVDXK1mOabIzEZ3FUoTqR8Ks+7aC4mBm8Gzi6m/M5ILHde08q/jpO6rt9NFFhYn/eExU5lcW1736ACX9f1brfj/RbEuxuk4VVBSkCP/L2WEZYL9pTLLT/X0r9h/Gac3ZzxXiF8W0FrGHsVM68q97ZMqMMaycCt5NnimiGitX+lr11r7TgOF5KId9docWOUPHdiHPrBK2wWwS1DOOCJ64x2u51cGVgsSDbzYoJXRd7F2F2JH6wRyvrOEtcw/Cp+XlXubZkYXPEvA8huce22GK++NYzNNE1xUGkcx8XzXiQEzxfu7Xjkd5sBSzZswErgB0vA4trGxs3zXDogcAgcl18u+mJRDBRpXC+FXaybf40JamM1bDYrgZ8oAYtrG1t17kTzfR9nBiTebaRus1kJWAk8IAGLa1uEt2hs4hPu3Mq/ha7NYyVgJfAMCVhc2yLFsizlplOQ4P1L1kLcIlObx0rgeRKwuHafLPG5E8dxPM+bn8G+XC43nGv3lWRTWwlYCWyVgMW1+ySH75INw4APXjAz98ffq6yBFOlcC4AsDkVdS2PjrQSsBCABi2sbe8IifhF91hON43hu0s6z43xlHMePXBE+J2tjrAR+pAQsrr2sWSUILqKkwRnOi8hLMowE9q+VgJUAJGBx7TU9AXYrTs7zApZrrBD1jG8eX0tv460E/nEJWFx7TQfABRLyQ+i42hhfXZG/8hLduq6/6Frq10jBlmol8DUSsLj2NXJdQbWqqrqueZkUViTwLSJcEIqwvCHW6msr5GqTWAlMFtde1glwVzXv/DLuKqD3jUYoLly06wYvazBb8N8jAYtrr2krfuKbt6Thu0Hzj8/L20GsHfqa1rKl/m0SsLj2shbDZdld12Gfh9TLwBNjoMqN45hlmeu68oNeL+PeFmwl8MYSsLj2msYBZhVFwdsoF1dFJbSVZVlVFX6Ny6NfUwdbqpXAu0rA4trLWoZHFOaIRjgDc4br7WUc24KtBP4SCfwXsHoollbdwC8AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was, therefore, imperative that a new metric be sought for. Logarithmic loss, commonly known as a loss function, handles the trade-off between accuracy and confidence.\n",
    "Mathematically, \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- N = Number of observations(rows) in the data set.\n",
    "- y = Actual target variable value of the observation (0 or 1)\n",
    "- p = Probability that the target variable value is 1.\n",
    "\n",
    "The log loss of the estimator on the full data set is the mean of the log losses of all the observations in that data set.\n",
    "This function is converted to code in the compare_estimators module and its behaviour is observed in this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_estimators import compute_log_loss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration 1 :Confident and wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302585092994046"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_log_loss(predicted=0.9, actual=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration 2: Unsure and right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_log_loss(0.5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is better (that is, log loss is lesser) when the model is right than when it is wrong and confident. Log loss emphasizes that the prediction should be right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the log loss value.\n",
    "\n",
    "A number of arrays are formed which are used to simulate the behaviour of log loss in all possible performance scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = np.array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
    "correct_confident = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.05, 0.05, 0.05, 0.05, 0.05])\n",
    "correct_not_confident = np.array([0.65, 0.65, 0.65, 0.65, 0.65, 0.35, 0.35, 0.35, 0.35, 0.35])\n",
    "wrong_not_confident = np.array([0.35, 0.35, 0.35, 0.35, 0.35, 0.65, 0.65, 0.65, 0.65, 0.65])\n",
    "wrong_confident = np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.95, 0.95, 0.95, 0.95, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss, correct and confident: 0.05129329438755058\n",
      "Log loss, correct and not confident: 0.4307829160924542\n",
      "Log loss, wrong and not confident: 1.049822124498678\n",
      "Log loss, wrong and confident: 2.9957322735539904\n",
      "Log loss, actual labels: 9.99200722162646e-15\n"
     ]
    }
   ],
   "source": [
    "# Compute and print log loss for 1st case\n",
    "correct_confident_loss = compute_log_loss(correct_confident, actual_labels)\n",
    "print(\"Log loss, correct and confident: {}\".format(correct_confident_loss)) \n",
    "\n",
    "# Compute log loss for 2nd case\n",
    "correct_not_confident_loss = compute_log_loss(correct_not_confident, actual_labels)\n",
    "print(\"Log loss, correct and not confident: {}\".format(correct_not_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for 3rd case\n",
    "wrong_not_confident_loss = compute_log_loss(wrong_not_confident, actual_labels)\n",
    "print(\"Log loss, wrong and not confident: {}\".format(wrong_not_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for 4th case\n",
    "wrong_confident_loss = compute_log_loss(wrong_confident, actual_labels)\n",
    "print(\"Log loss, wrong and confident: {}\".format(wrong_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for actual labels\n",
    "actual_labels_loss = compute_log_loss(actual_labels, actual_labels)\n",
    "print(\"Log loss, actual labels: {}\".format(actual_labels_loss)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance preferences of log loss, from greatest to least are:\n",
    "* correct and confident.\n",
    "* correct and unsure.\n",
    "* wrong and unsure.\n",
    "* wrong and confident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of a dataset, the `predicted` parameter values are the second column of the result of applying predict_proba() on the data set. That is, the probabilities that the target variable value is 1.\n",
    "On the other hand, the `actual` parameter values are equal to the `target_test` partition of `train_test_split`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

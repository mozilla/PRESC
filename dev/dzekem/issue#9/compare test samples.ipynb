{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "### Train and test a classification model(s) on the Default dataset.\n",
    "Before training a model on this dataset, a good understanding of each explanatory variable (features) is vital.\n",
    "### Definition of each feature\n",
    "\n",
    " - **limit_bal**: limit balance also known as credit limit is the **credit limit** after applying for a credit card determined by the credit card issuer.\n",
    " - **sex:** Sex of the credit card owner which is either 1 for **Male** or 2 for **Female**\n",
    " - **education:** Highest level of education for the credit card owner. where 1 = graduate school; 2 = university; 3 = high school; 4 = others\n",
    " - **marriage:** Marital status of credit card owner where 1 = married; 2 = single; 3 = others\n",
    " - **age:** Ages of card owners.\n",
    " - **pay_0 to pay_6:** History of past monthly pay records starting from April(pay_0) to September(pay_6) for each card owner.\n",
    "    statuses are 0: pay duly, 1: payment delay for one month, 2: payment delay for two months.\n",
    " - **bill_amtt1 to bill_amnt6** represents amount of bill statement from April(bill_amt1) to September(bill_amt6). \n",
    "    **Bill statement** is a periodic statement that lists all the payments, purchases and other debits and credits during the billing cycle.\n",
    " - **pay_amt1 to pay_amt6** is amount paid in the previous month. From April(pay_amt1) to September(pay_amt6)\n",
    " - **defaulted:** To defauult means failure to pay a debt on the agreed upon date. IN this case, creditors mostly raise interest rates or decrese the credit limit.\n",
    "        \n",
    "Since defaulted is the target variable in this case, suitable models will be used to train and test the other explanatory variables and see which model predicts with highest accuracy on the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  \n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>sex</th>\n",
       "      <th>education</th>\n",
       "      <th>marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>pay_0</th>\n",
       "      <th>pay_2</th>\n",
       "      <th>pay_3</th>\n",
       "      <th>pay_4</th>\n",
       "      <th>...</th>\n",
       "      <th>bill_amt4</th>\n",
       "      <th>bill_amt5</th>\n",
       "      <th>bill_amt6</th>\n",
       "      <th>pay_amt1</th>\n",
       "      <th>pay_amt2</th>\n",
       "      <th>pay_amt3</th>\n",
       "      <th>pay_amt4</th>\n",
       "      <th>pay_amt5</th>\n",
       "      <th>pay_amt6</th>\n",
       "      <th>defaulted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  limit_bal  sex  education  marriage  age  pay_0  pay_2  pay_3  pay_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "     ...      bill_amt4  bill_amt5  bill_amt6  pay_amt1  pay_amt2  pay_amt3  \\\n",
       "0    ...              0          0          0         0       689         0   \n",
       "1    ...           3272       3455       3261         0      1000      1000   \n",
       "2    ...          14331      14948      15549      1518      1500      1000   \n",
       "3    ...          28314      28959      29547      2000      2019      1200   \n",
       "4    ...          20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   pay_amt4  pay_amt5  pay_amt6  defaulted  \n",
       "0         0         0         0          1  \n",
       "1      1000         0      2000          1  \n",
       "2      1000      1000      5000          0  \n",
       "3      1100      1069      1000          0  \n",
       "4      9000       689       679          0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('defaults.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Data cleaning and preprocessing.\n",
    "At this point, cleaning is done by ensuring there are no missing values or \n",
    "wrong input values by following the dataset description and the data given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>sex</th>\n",
       "      <th>education</th>\n",
       "      <th>marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>pay_0</th>\n",
       "      <th>pay_2</th>\n",
       "      <th>pay_3</th>\n",
       "      <th>pay_4</th>\n",
       "      <th>...</th>\n",
       "      <th>bill_amt4</th>\n",
       "      <th>bill_amt5</th>\n",
       "      <th>bill_amt6</th>\n",
       "      <th>pay_amt1</th>\n",
       "      <th>pay_amt2</th>\n",
       "      <th>pay_amt3</th>\n",
       "      <th>pay_amt4</th>\n",
       "      <th>pay_amt5</th>\n",
       "      <th>pay_amt6</th>\n",
       "      <th>defaulted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>167484.322667</td>\n",
       "      <td>1.603733</td>\n",
       "      <td>1.853133</td>\n",
       "      <td>1.551867</td>\n",
       "      <td>35.485500</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>-0.133767</td>\n",
       "      <td>-0.166200</td>\n",
       "      <td>-0.220667</td>\n",
       "      <td>...</td>\n",
       "      <td>43262.948967</td>\n",
       "      <td>40311.400967</td>\n",
       "      <td>38871.760400</td>\n",
       "      <td>5663.580500</td>\n",
       "      <td>5.921163e+03</td>\n",
       "      <td>5225.68150</td>\n",
       "      <td>4826.076867</td>\n",
       "      <td>4799.387633</td>\n",
       "      <td>5215.502567</td>\n",
       "      <td>0.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8660.398374</td>\n",
       "      <td>129747.661567</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.790349</td>\n",
       "      <td>0.521970</td>\n",
       "      <td>9.217904</td>\n",
       "      <td>1.123802</td>\n",
       "      <td>1.197186</td>\n",
       "      <td>1.196868</td>\n",
       "      <td>1.169139</td>\n",
       "      <td>...</td>\n",
       "      <td>64332.856134</td>\n",
       "      <td>60797.155770</td>\n",
       "      <td>59554.107537</td>\n",
       "      <td>16563.280354</td>\n",
       "      <td>2.304087e+04</td>\n",
       "      <td>17606.96147</td>\n",
       "      <td>15666.159744</td>\n",
       "      <td>15278.305679</td>\n",
       "      <td>17777.465775</td>\n",
       "      <td>0.415062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7500.750000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2326.750000</td>\n",
       "      <td>1763.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.330000e+02</td>\n",
       "      <td>390.00000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>252.500000</td>\n",
       "      <td>117.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19052.000000</td>\n",
       "      <td>18104.500000</td>\n",
       "      <td>17071.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1800.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22500.250000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54506.000000</td>\n",
       "      <td>50190.500000</td>\n",
       "      <td>49198.250000</td>\n",
       "      <td>5006.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4505.00000</td>\n",
       "      <td>4013.250000</td>\n",
       "      <td>4031.500000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.00000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       limit_bal           sex     education      marriage  \\\n",
       "count  30000.000000    30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean   15000.500000   167484.322667      1.603733      1.853133      1.551867   \n",
       "std     8660.398374   129747.661567      0.489129      0.790349      0.521970   \n",
       "min        1.000000    10000.000000      1.000000      0.000000      0.000000   \n",
       "25%     7500.750000    50000.000000      1.000000      1.000000      1.000000   \n",
       "50%    15000.500000   140000.000000      2.000000      2.000000      2.000000   \n",
       "75%    22500.250000   240000.000000      2.000000      2.000000      2.000000   \n",
       "max    30000.000000  1000000.000000      2.000000      6.000000      3.000000   \n",
       "\n",
       "                age         pay_0         pay_2         pay_3         pay_4  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean      35.485500     -0.016700     -0.133767     -0.166200     -0.220667   \n",
       "std        9.217904      1.123802      1.197186      1.196868      1.169139   \n",
       "min       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       79.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "           ...           bill_amt4      bill_amt5      bill_amt6  \\\n",
       "count      ...        30000.000000   30000.000000   30000.000000   \n",
       "mean       ...        43262.948967   40311.400967   38871.760400   \n",
       "std        ...        64332.856134   60797.155770   59554.107537   \n",
       "min        ...      -170000.000000  -81334.000000 -339603.000000   \n",
       "25%        ...         2326.750000    1763.000000    1256.000000   \n",
       "50%        ...        19052.000000   18104.500000   17071.000000   \n",
       "75%        ...        54506.000000   50190.500000   49198.250000   \n",
       "max        ...       891586.000000  927171.000000  961664.000000   \n",
       "\n",
       "            pay_amt1      pay_amt2      pay_amt3       pay_amt4  \\\n",
       "count   30000.000000  3.000000e+04   30000.00000   30000.000000   \n",
       "mean     5663.580500  5.921163e+03    5225.68150    4826.076867   \n",
       "std     16563.280354  2.304087e+04   17606.96147   15666.159744   \n",
       "min         0.000000  0.000000e+00       0.00000       0.000000   \n",
       "25%      1000.000000  8.330000e+02     390.00000     296.000000   \n",
       "50%      2100.000000  2.009000e+03    1800.00000    1500.000000   \n",
       "75%      5006.000000  5.000000e+03    4505.00000    4013.250000   \n",
       "max    873552.000000  1.684259e+06  896040.00000  621000.000000   \n",
       "\n",
       "            pay_amt5       pay_amt6     defaulted  \n",
       "count   30000.000000   30000.000000  30000.000000  \n",
       "mean     4799.387633    5215.502567      0.221200  \n",
       "std     15278.305679   17777.465775      0.415062  \n",
       "min         0.000000       0.000000      0.000000  \n",
       "25%       252.500000     117.750000      0.000000  \n",
       "50%      1500.000000    1500.000000      0.000000  \n",
       "75%      4031.500000    4000.000000      0.000000  \n",
       "max    426529.000000  528666.000000      1.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The inbuilt function describes gives more details for all numerical features and since all the features here are numerical, the description is given for all of them.\n",
    " - prints out the counts of all the records for each feature, mean, standard deviation, min, max and percentile values. This helps better understand the nature of the explanatory variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 25 columns):\n",
      "id           30000 non-null int64\n",
      "limit_bal    30000 non-null int64\n",
      "sex          30000 non-null int64\n",
      "education    30000 non-null int64\n",
      "marriage     30000 non-null int64\n",
      "age          30000 non-null int64\n",
      "pay_0        30000 non-null int64\n",
      "pay_2        30000 non-null int64\n",
      "pay_3        30000 non-null int64\n",
      "pay_4        30000 non-null int64\n",
      "pay_5        30000 non-null int64\n",
      "pay_6        30000 non-null int64\n",
      "bill_amt1    30000 non-null int64\n",
      "bill_amt2    30000 non-null int64\n",
      "bill_amt3    30000 non-null int64\n",
      "bill_amt4    30000 non-null int64\n",
      "bill_amt5    30000 non-null int64\n",
      "bill_amt6    30000 non-null int64\n",
      "pay_amt1     30000 non-null int64\n",
      "pay_amt2     30000 non-null int64\n",
      "pay_amt3     30000 non-null int64\n",
      "pay_amt4     30000 non-null int64\n",
      "pay_amt5     30000 non-null int64\n",
      "pay_amt6     30000 non-null int64\n",
      "defaulted    30000 non-null int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information printed for the dataframe prints out data types of all the features and also missing values could be determined from here since the total number of records is printed out for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "data.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inbuilt function isnull() prints out any null(undefined or empty space) values and which feature the record belongs. \n",
    "In this case there is no null value which therefore helps proceed to the next level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with and without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  <class 'numpy.ndarray'> (30000, 23)\n",
      "y:  <class 'numpy.ndarray'> (30000,)\n",
      "Accuracy of the logistic regression model on the training and test set is\n",
      "[Train] Accuracy score is:  0.7783\n",
      "[Test] Accuracy score is:  0.7803\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression is a scikit learn model so it must be imported from sklearn, train_test_split and also accuracy score are all imported from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = data.iloc[:, 1:24].values\n",
    "print('X: ', type(X), X.shape)\n",
    "y = data.iloc[:, 24].values\n",
    "print('y: ', type(y), y.shape)\n",
    "\n",
    "# Splitting the data into train and test set in the ratio 80:20\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "print(\"Accuracy of the logistic regression model on the training and test set is\" )\n",
    "\n",
    "clf_lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "clf_lr.fit(Xtrain, ytrain)\n",
    "\n",
    "y_pred_train = clf_lr.predict(Xtrain)\n",
    "print('[Train] Accuracy score is: ', round(accuracy_score(ytrain, y_pred_train), 4))\n",
    "      \n",
    "y_pred_test = clf_lr.predict(Xtest)\n",
    "print('[Test] Accuracy score is: ', round(accuracy_score(y_pred_test, ytest), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings from above model.\n",
    " - After splitting the data into test and train, logistic regression model was used which gave an accuracy score of 0.7783 on th train set and an accuracy score of 0.7803 for the test set.\n",
    " - This score is the best for a machine learning predictions. This therefore is the reason why when making predictions, two or more models are always tested to see which produces best accuracy results without overfitting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Regularization\n",
    "This is called parameter tuning where the model parameters are changed from the default values so as to better optimize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Accuracy score is:  0.81\n",
      "[Test] Accuracy score is:  0.8128\n"
     ]
    }
   ],
   "source": [
    "# logistic regression classifier with regularization set to l1.\n",
    "clf_lr2 = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "\n",
    "clf_lr2.fit(Xtrain, ytrain)\n",
    "\n",
    "y_pred_train2= clf_lr2.predict(Xtrain)\n",
    "print('[Train] Accuracy score is: ', round(accuracy_score(ytrain, y_pred_train2), 4))\n",
    "      \n",
    "y_pred_test2 = clf_lr2.predict(Xtest)\n",
    "print('[Test] Accuracy score is: ', round(accuracy_score(y_pred_test2, ytest), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings from Logistic Regression model with Regularization\n",
    " - Logistic regression model comes with some parameters including penalty. Penalty by default comes with the logistic regression model as l2. Regularixation is a techniwue used to prevent overfitting the model. When L1 is used, the regularization is called Lasso Regression. L1 not only helps reduce model overfitting, it also makes it's data sparce when most of it's cells are zero.\n",
    " - Thaccuracy score using regularization is higher and without model overfitting. This could therefore be a good option for predictions to be done with this data as the accuracy scores of the model is >0.8 for both train and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Accuracy score using Decision Tree Model is:  0.9995\n",
      "[Test] Accuracy score using Decision Tree Model is:  0.7293\n"
     ]
    }
   ],
   "source": [
    "# Importing DecisionTree classifier from sklearn.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dt = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "clf_dt.fit(Xtrain, ytrain)\n",
    "\n",
    "\n",
    "y_pred_dt = clf_dt.predict(Xtrain)\n",
    "print('[Train] Accuracy score using Decision Tree Model is: ', round(accuracy_score(ytrain, y_pred_dt), 4))\n",
    "      \n",
    "y_pred_dt2 = clf_dt.predict(Xtest)\n",
    "print('[Test] Accuracy score using Decision Tree Model is: ', round(accuracy_score(y_pred_dt2, ytest), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations from Decision Tree Model\n",
    " - The accuracy score of the Decision tree model on the train set is 0.999 whereas the accuracy score for the test data is just 0.7248. \n",
    " - There is model overfitting as the model turns to train the data too well thereby producing accuracy score of 0.999 with minimal modelling error.\n",
    " - Due to the model being too complex and trying to be perfect, the test values turned to be too low as the predictions were mostly faulty.\n",
    " - Decision trees is therefore not a good option for this case as there is model overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to optimize this Decision Tree model\n",
    "- Overfitting turns to be common when implementing a decision tree model on large data. This is due to the long decision chain that results from many branches and leaves that were expanded from the data especially when the dataset has many explanatory variables(features)\n",
    "- One way to resolve this issue of model overfitting is by implementing hyper parameter tuning or Pruning\n",
    "- **Pruning** is a techniwue of reducing the size of a decision tree by removing some sections from the tree that do not have the power to classify instances. \n",
    "- In this case, the Decision tree model will be optimized by modifying default parameter values which is a means of reducing the tree size and the depth as the more the tree grows, the more the algorithm turns to be more complex thus resulting to model overfitting.\n",
    "- Two main parameters will be tested and that with optimal solution will be used to optimize the model. They are:\n",
    "- **Max_depth:** This integer value defines the maximum depth of the tree.\n",
    "- **Min_samples_split:** This is the minimum number of samples required to split a node.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Accuracy score using Decision Tree Model with parameter tuning is:  0.8247\n",
      "[Test] Accuracy score using Decision Tree Model with parameter tuning is:  0.8177\n"
     ]
    }
   ],
   "source": [
    "# Optimized model for the decision tree.\n",
    "# Parameters modified are min_samples_split and max_depth\n",
    "clf_dt2 = DecisionTreeClassifier(criterion='entropy', min_samples_split=300, max_depth=10, random_state=0)\n",
    "clf_dt2.fit(Xtrain, ytrain)\n",
    "\n",
    "\n",
    "ypred_dt = clf_dt2.predict(Xtrain)\n",
    "print('[Train] Accuracy score using Decision Tree Model with parameter tuning is: ', round(accuracy_score(ytrain, ypred_dt), 4))\n",
    "      \n",
    "ypred_dt2 = clf_dt2.predict(Xtest)\n",
    "print('[Test] Accuracy score using Decision Tree Model with parameter tuning is: ', round(accuracy_score(ypred_dt2, ytest), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findindings after parameter tuning\n",
    " - After creating a classifier with modified parameter values, Decision tree model no longer overfits the data and produces the best accuracy score compared to the other models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion Matrix from the test data\n",
      "[[4682    1]\n",
      " [1317    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xbb5e550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(ytest, y_pred_test)\n",
    "print('Confussion Matrix from the test data')\n",
    "print(cf_matrix)\n",
    "\n",
    "labels = ['Correct \\n True Negative','Wrong \\n False Positive','Wrong \\n False Negative','Correct \\n True Positive']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations from the confussion matrix above\n",
    "- A confussion matrix is used to measure the performance of a machine learning classifcation model. Also known as the error matrix brings out the visualization of the performance of a classification model.\n",
    "- From the visualizations above, there are four different sections with different with statistics about the model performance on this data. \n",
    "- From a data set of 30000 entries(records), 20% was to test the model which makes a total of 6000 records. The model perfomance on this data therefore gives statistics of the predictions on the table above which is:  \n",
    "- **4566 TN(True Negatives):** Records that were  predicted as non defaulted and they actually are\n",
    "- **117 FP(False Positives):** Non defaulted cards but classified as defaulted\n",
    "- **1006 FN(False Negatives):** Defaulted cards instead classififed under non defaulted cards. \n",
    "- **311 TP(True Positives):** Records that were predicted as defaulted when actually they cards were defaulted.\n",
    "- TP and FP are assigned to the **Positive class**(Defaulted cards) while TN and FN are assigned to the **negative class**(Non defaulted cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     18681\n",
      "           1       0.71      0.24      0.36      5319\n",
      "\n",
      "    accuracy                           0.81     24000\n",
      "   macro avg       0.76      0.61      0.62     24000\n",
      "weighted avg       0.79      0.81      0.77     24000\n",
      "\n",
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89      5572\n",
      "           1       0.24      0.73      0.36       428\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.61      0.77      0.62      6000\n",
      "weighted avg       0.92      0.81      0.85      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for Logistic regression with L1 regularization\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"[Training Classification Report:]\")\n",
    "print(classification_report(ytrain, y_pred_train2))\n",
    "\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(y_pred_test2, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "A classification report is used to measure the efficiency of a classification model by printing out on a table howmany predictions are true and howmany are false.\n",
    " - **Precision** is the ability of this model not to lable a record positive(defaulted card) whereas it is actually negative(non defaulted card).\n",
    " - **Recall** This is the ability of this model to find all positive instances. Positive instances is a sum of True Negative(TN) and False Negative(FN)\n",
    " - **F1 score** is the weighted harmonic mean of precision and recall where the best score is 1.0 and the worst is 0. This cannot be compared to model accuracy as it adds up the recall and precision during it's computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4449  234]\n",
      " [ 860  457]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xc973ba8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(ytest, ypred_dt2)\n",
    "print(cf_matrix)\n",
    "\n",
    "labels = ['Correct \\n True Negative','Wrong \\n False Positive','Wrong \\n False Negative','Correct \\n True Positive']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='rainbow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     18681\n",
      "           1       0.69      0.38      0.49      5319\n",
      "\n",
      "    accuracy                           0.82     24000\n",
      "   macro avg       0.77      0.66      0.69     24000\n",
      "weighted avg       0.81      0.82      0.80     24000\n",
      "\n",
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89      5309\n",
      "           1       0.35      0.66      0.46       691\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.65      0.75      0.67      6000\n",
      "weighted avg       0.88      0.82      0.84      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for Decision tree with hyperparameter tuning\n",
    "\n",
    "print(\"[Training Classification Report:]\")\n",
    "print(classification_report(ytrain, ypred_dt))\n",
    "\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(ypred_dt2, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations from classification report of Decision tree with fewer leaves\n",
    " - Since precision is the ability of a model not to label a record positive(defaulted) whereas it is actually negative. This therefore means greater precisions reducing the chances of making wrong predictions.\n",
    " - From above, the precision values of the decisison tree are higher than those for logistic regression which show how accurate the decisison tree model will perform with any other foreign data.\n",
    " - Recall values are also high for this model which is the ability of the model to be able to find all positive instances. Positive instances are sum of True Negative and False Negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89252615, 0.10747385],\n",
       "       [0.61130159, 0.38869841],\n",
       "       [0.98315197, 0.01684803],\n",
       "       [0.99068021, 0.00931979],\n",
       "       [0.67551926, 0.32448074]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "log_prediction = clf_lr.predict_proba(Xtest)\n",
    "# Gives probabilities of the target(0 and 1) in the form of an array. For Logistic regression with regularization\n",
    "\n",
    "dt_prediction = clf_dt2.predict_proba(Xtest)\n",
    "# Probabilities of the target for Decision tree\n",
    "\n",
    "# print out of probability predictions from logistic regression\n",
    "log_prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logPred0</th>\n",
       "      <th>logPred1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.892526</td>\n",
       "      <td>0.107474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.611302</td>\n",
       "      <td>0.388698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.983152</td>\n",
       "      <td>0.016848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.990680</td>\n",
       "      <td>0.009320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.675519</td>\n",
       "      <td>0.324481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   logPred0  logPred1\n",
       "0  0.892526  0.107474\n",
       "1  0.611302  0.388698\n",
       "2  0.983152  0.016848\n",
       "3  0.990680  0.009320\n",
       "4  0.675519  0.324481"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the numpy array log_prediction(Logistic regression) to a dataframe.\n",
    "df_log = pd.DataFrame(data=log_prediction, columns=[\"logPred0\", \"logPred1\"])\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logPred0</th>\n",
       "      <th>logPred1</th>\n",
       "      <th>dt_Pred0</th>\n",
       "      <th>dt_Pred1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.892526</td>\n",
       "      <td>0.107474</td>\n",
       "      <td>0.904661</td>\n",
       "      <td>0.095339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.611302</td>\n",
       "      <td>0.388698</td>\n",
       "      <td>0.650138</td>\n",
       "      <td>0.349862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.983152</td>\n",
       "      <td>0.016848</td>\n",
       "      <td>0.958716</td>\n",
       "      <td>0.041284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.990680</td>\n",
       "      <td>0.009320</td>\n",
       "      <td>0.958716</td>\n",
       "      <td>0.041284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.675519</td>\n",
       "      <td>0.324481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   logPred0  logPred1  dt_Pred0  dt_Pred1\n",
       "0  0.892526  0.107474  0.904661  0.095339\n",
       "1  0.611302  0.388698  0.650138  0.349862\n",
       "2  0.983152  0.016848  0.958716  0.041284\n",
       "3  0.990680  0.009320  0.958716  0.041284\n",
       "4  0.675519  0.324481  1.000000  0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dt = pd.DataFrame(data=dt_prediction, columns=[\"dt_Pred0\", \"dt_Pred1\"])\n",
    "#An inner join is performed to join both dataframes\n",
    "final = df_log.join(df_dt)\n",
    "\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Predicted Prebabilities for class 0 with both models')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar chart for the predict probabilities on the class 0 for both models.\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "log0, a_bins = np.histogram(final['logPred0'])\n",
    "dt0, b_bins = np.histogram(final['dt_Pred0'], bins=a_bins)\n",
    "\n",
    "width = (a_bins[1] - a_bins[0])/3\n",
    "\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.bar(a_bins[:-1], log0, width=width, facecolor='cornflowerblue', label='Logistic reg')\n",
    "plt.bar(b_bins[:-1]+width, dt0, width=width, facecolor='seagreen', label='Decision tree')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title('Predicted Prebabilities for class 0 with both models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations from probability predictions from both models considering the 0 class\n",
    " - The bar chart above shows probability predictions performed on both Logistic Regression and Decision tree model. \n",
    " - This visualization is only for the class 0 which is credit card accounts that were not defaulted.\n",
    " - This shows that the model with highest and best prediction probabilities is the Decision tree model.\n",
    " - This visualization also helps visualize the rate at which the model misclassifices during predictions which is looking at the amount of counts for probabilities lower then 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

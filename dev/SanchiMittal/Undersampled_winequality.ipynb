{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  recommend  \n",
       "0         8.8        6      False  \n",
       "1         9.5        6      False  \n",
       "2        10.1        6      False  \n",
       "3         9.9        6      False  \n",
       "4         9.9        6      False  \n",
       "...       ...      ...        ...  \n",
       "4893     11.2        6      False  \n",
       "4894      9.6        5      False  \n",
       "4895      9.4        6      False  \n",
       "4896     12.8        7       True  \n",
       "4897     11.8        6      False  \n",
       "\n",
       "[4898 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataloader as dl # module for loading and pre-processing the data\n",
    "import models_eval as mev # module for model training and testing\n",
    "d = dl.load_dataset()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points:  4898\n",
      "Percentage of individual target class:\n",
      " False    78.358514\n",
      "True     21.641486\n",
      "Name: recommend, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d[\"recommend\"].value_counts().plot(kind=\"bar\")\n",
    "print(\"Total data points: \",len(d))\n",
    "print(\"Percentage of individual target class:\\n\",d[\"recommend\"].value_counts()/len(d)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that 'False' is the majority class here, that is target labels are non-uniformly distributed throughout the dataset with much higher 'False' labels than the 'True' labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will create a random sample (without replacement) from the majority class with various proportions of number of minority class data points and concatenate it with the minority class data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.044</td>\n",
       "      <td>48.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>12.4</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.032</td>\n",
       "      <td>28.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.99140</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.4</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.029</td>\n",
       "      <td>29.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.98920</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.39</td>\n",
       "      <td>12.8</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.029</td>\n",
       "      <td>29.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.98920</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.39</td>\n",
       "      <td>12.8</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.038</td>\n",
       "      <td>19.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.35</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.041</td>\n",
       "      <td>26.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.99428</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.053</td>\n",
       "      <td>61.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.99112</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.68</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.056</td>\n",
       "      <td>56.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.99670</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.44</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.009</td>\n",
       "      <td>65.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.98740</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.37</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.033</td>\n",
       "      <td>28.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.99684</td>\n",
       "      <td>2.87</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2120 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               6.6              0.16         0.40             1.5      0.044   \n",
       "1               6.6              0.17         0.38             1.5      0.032   \n",
       "2               6.2              0.66         0.48             1.2      0.029   \n",
       "3               6.2              0.66         0.48             1.2      0.029   \n",
       "4               6.4              0.31         0.38             2.9      0.038   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "2115            6.9              0.30         0.25             3.3      0.041   \n",
       "2116            6.4              0.15         0.40             1.3      0.053   \n",
       "2117            6.9              0.29         0.23             8.6      0.056   \n",
       "2118            5.0              0.61         0.12             1.3      0.009   \n",
       "2119            6.1              0.17         0.42            15.1      0.033   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    48.0                 143.0  0.99120  3.54       0.52   \n",
       "1                    28.0                 112.0  0.99140  3.25       0.55   \n",
       "2                    29.0                  75.0  0.98920  3.33       0.39   \n",
       "3                    29.0                  75.0  0.98920  3.33       0.39   \n",
       "4                    19.0                 102.0  0.99120  3.17       0.35   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "2115                 26.0                 124.0  0.99428  3.18       0.50   \n",
       "2116                 61.0                 146.0  0.99112  3.17       0.68   \n",
       "2117                 56.0                 215.0  0.99670  3.17       0.44   \n",
       "2118                 65.0                 100.0  0.98740  3.26       0.37   \n",
       "2119                 28.0                 124.0  0.99684  2.87       0.47   \n",
       "\n",
       "      alcohol  quality  recommend  \n",
       "0        12.4        7       True  \n",
       "1        11.4        7       True  \n",
       "2        12.8        8       True  \n",
       "3        12.8        8       True  \n",
       "4        11.0        7       True  \n",
       "...       ...      ...        ...  \n",
       "2115      9.3        6      False  \n",
       "2116     11.0        6      False  \n",
       "2117      8.8        5      False  \n",
       "2118     13.5        5      False  \n",
       "2119      9.5        5      False  \n",
       "\n",
       "[2120 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.np.random.seed(42)\n",
    "under_sample = dl.undersample(d) # default minority proprtion= 0.5\n",
    "under_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9d1a4d8610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "under_sample[\"recommend\"].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=0.4,\n",
      "            train_size=None)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = dl.PreProcess_and_Split(under_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled data with minority proportion: 0.5 and Random Forest Classification model\n",
      "Test data ratio: 0.4\n",
      "StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=0.4,\n",
      "            train_size=None)\n",
      "Confusion matrix:\n",
      "[[341  83]\n",
      " [ 72 352]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "81.72169811320755 %\n",
      "\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.80      0.81       424\n",
      "        True       0.81      0.83      0.82       424\n",
      "\n",
      "    accuracy                           0.82       848\n",
      "   macro avg       0.82      0.82      0.82       848\n",
      "weighted avg       0.82      0.82      0.82       848\n",
      "\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Undersampled data with minority proportion: 0.5 and Random Forest Classification model\n",
      "Test data ratio: 0.3\n",
      "StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=0.3,\n",
      "            train_size=None)\n",
      "Confusion matrix:\n",
      "[[265  53]\n",
      " [ 57 261]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "82.70440251572327 %\n",
      "\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.83      0.83       318\n",
      "        True       0.83      0.82      0.83       318\n",
      "\n",
      "    accuracy                           0.83       636\n",
      "   macro avg       0.83      0.83      0.83       636\n",
      "weighted avg       0.83      0.83      0.83       636\n",
      "\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Undersampled data with minority proportion: 0.5 and Random Forest Classification model\n",
      "Test data ratio: 0.2\n",
      "StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=0.2,\n",
      "            train_size=None)\n",
      "Confusion matrix:\n",
      "[[185  27]\n",
      " [ 32 180]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "86.08490566037736 %\n",
      "\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.87      0.86       212\n",
      "        True       0.87      0.85      0.86       212\n",
      "\n",
      "    accuracy                           0.86       424\n",
      "   macro avg       0.86      0.86      0.86       424\n",
      "weighted avg       0.86      0.86      0.86       424\n",
      "\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Undersampled data with minority proportion: 0.33 and Random Forest Classification model\n",
      "Test data ratio: 0.4\n",
      "StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=0.4,\n",
      "            train_size=None)\n",
      "Confusion matrix:\n",
      "[[776  85]\n",
      " [107 317]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "85.05836575875486 %\n",
      "\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.90      0.89       861\n",
      "        True       0.79      0.75      0.77       424\n",
      "\n",
      "    accuracy                           0.85      1285\n",
      "   macro avg       0.83      0.82      0.83      1285\n",
      "weighted avg       0.85      0.85      0.85      1285\n",
      "\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Undersampled data with minority proportion: 0.33 and Random Forest Classification model\n",
      "Test data ratio: 0.3\n",
      "StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=0.3,\n",
      "            train_size=None)\n",
      "Confusion matrix:\n",
      "[[587  59]\n",
      " [ 77 241]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "85.89211618257261 %\n",
      "\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.91      0.90       646\n",
      "        True       0.80      0.76      0.78       318\n",
      "\n",
      "    accuracy                           0.86       964\n",
      "   macro avg       0.84      0.83      0.84       964\n",
      "weighted avg       0.86      0.86      0.86       964\n",
      "\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Undersampled data with minority proportion: 0.33 and Random Forest Classification model\n",
      "Test data ratio: 0.2\n",
      "StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=0.2,\n",
      "            train_size=None)\n",
      "Confusion matrix:\n",
      "[[402  29]\n",
      " [ 60 152]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "86.15863141524106 %\n",
      "\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.93      0.90       431\n",
      "        True       0.84      0.72      0.77       212\n",
      "\n",
      "    accuracy                           0.86       643\n",
      "   macro avg       0.85      0.82      0.84       643\n",
      "weighted avg       0.86      0.86      0.86       643\n",
      "\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Undersampled data with minority proportion: 0.25 and Random Forest Classification model\n",
      "Test data ratio: 0.4\n",
      "StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=0.4,\n",
      "            train_size=None)\n",
      "Confusion matrix:\n",
      "[[1198   74]\n",
      " [ 147  277]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "86.96933962264151 %\n",
      "\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.94      0.92      1272\n",
      "        True       0.79      0.65      0.71       424\n",
      "\n",
      "    accuracy                           0.87      1696\n",
      "   macro avg       0.84      0.80      0.82      1696\n",
      "weighted avg       0.87      0.87      0.87      1696\n",
      "\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Undersampled data with minority proportion: 0.25 and Random Forest Classification model\n",
      "Test data ratio: 0.3\n",
      "StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=0.3,\n",
      "            train_size=None)\n",
      "Confusion matrix:\n",
      "[[915  39]\n",
      " [ 97 221]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "89.30817610062893 %\n",
      "\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.96      0.93       954\n",
      "        True       0.85      0.69      0.76       318\n",
      "\n",
      "    accuracy                           0.89      1272\n",
      "   macro avg       0.88      0.83      0.85      1272\n",
      "weighted avg       0.89      0.89      0.89      1272\n",
      "\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Undersampled data with minority proportion: 0.25 and Random Forest Classification model\n",
      "Test data ratio: 0.2\n",
      "StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=0.2,\n",
      "            train_size=None)\n",
      "Confusion matrix:\n",
      "[[615  21]\n",
      " [ 60 152]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "90.44811320754717 %\n",
      "\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.97      0.94       636\n",
      "        True       0.88      0.72      0.79       212\n",
      "\n",
      "    accuracy                           0.90       848\n",
      "   macro avg       0.89      0.84      0.86       848\n",
      "weighted avg       0.90      0.90      0.90       848\n",
      "\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dl.np.random.seed(42)\n",
    "minority_proportion = [0.5, 0.33, 0.25]\n",
    "test_size = [0.4, 0.3, 0.2]\n",
    "for m in minority_proportion:\n",
    "    for t in test_size:\n",
    "        print('Undersampled data with minority proportion:', m, 'and Random Forest Classification model')\n",
    "        print('Test data ratio:', t)\n",
    "        under_sample = dl.undersample(d, m)\n",
    "        x_train, x_test, y_train, y_test = dl.PreProcess_and_Split(under_sample, t)\n",
    "        undersampled_y_pred = mev.RFC(x_train, x_test, y_train) #predicted target values\n",
    "        mev.Performance_Eval(y_test, undersampled_y_pred) \n",
    "        print('\\n-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 14  33]\n",
      " [  4 420]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "92.1443736730361 %\n",
      "\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.30      0.43        47\n",
      "        True       0.93      0.99      0.96       424\n",
      "\n",
      "    accuracy                           0.92       471\n",
      "   macro avg       0.85      0.64      0.69       471\n",
      "weighted avg       0.91      0.92      0.91       471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "undersampled_y_pred = mev.RFC(x_train, x_test, y_train) #predicted target values\n",
    "mev.Performance_Eval(y_test, undersampled_y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the undersampling has been performed without replacement to avoid the training of model on same data points again and again which could result in biased accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
